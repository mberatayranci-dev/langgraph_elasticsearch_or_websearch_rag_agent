"""
LangGraph Node fonksiyonlarÄ±
"""
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage

from .state import AgentState
from .tools import web_search
from .config import LLM_MODEL, LLM_TEMPERATURE, DEBUG


# LLM baÅŸlatma
llm = ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE)

# VectorStore global deÄŸiÅŸken (graph.py'den set edilecek)
vectorstore_manager = None


def set_vectorstore(vs_manager):
    """VectorStore manager'Ä± set eder"""
    global vectorstore_manager
    vectorstore_manager = vs_manager


def classify_query(state: AgentState) -> AgentState:
    """
    Sorunun Elasticsearch ile ilgili olup olmadÄ±ÄŸÄ±nÄ± belirler.
    
    Args:
        state: Mevcut agent state
        
    Returns:
        GÃ¼ncellenmiÅŸ state
    """
    last_message = state["messages"][-1].content
    
    classification_prompt = f"""
    AÅŸaÄŸÄ±daki soru Elasticsearch ile ilgili mi? 
    Elasticsearch hakkÄ±nda kurulum, kullanÄ±m, Ã¶zellikler, sorgular, aggregation gibi konulardan bahsediyorsa EVET.
    BaÅŸka bir konu hakkÄ±ndaysa HAYIR cevabÄ± ver.
    
    Sadece 'EVET' veya 'HAYIR' cevabÄ± ver, baÅŸka bir ÅŸey yazma.
    
    Soru: {last_message}
    
    Cevap:"""
    
    response = llm.invoke(classification_prompt)
    is_es_related = "EVET" in response.content.upper()
    
    state["is_elasticsearch_related"] = is_es_related
    
    # Debug iÃ§in
    if DEBUG:
        print(f"ğŸ” Soru sÄ±nÄ±flandÄ±rmasÄ±: {'Elasticsearch' if is_es_related else 'Genel'}")
    
    return state


def retrieve_from_docs(state: AgentState) -> AgentState:
    """
    Elasticsearch dÃ¶kÃ¼manlarÄ±ndan ilgili bilgileri alÄ±r.
    
    Args:
        state: Mevcut agent state
        
    Returns:
        GÃ¼ncellenmiÅŸ state
    """
    if not state["is_elasticsearch_related"]:
        return state
    
    last_message = state["messages"][-1].content
    
    if DEBUG:
        print("ğŸ“š DÃ¶kÃ¼manlardan bilgi alÄ±nÄ±yor...")
    
    # VectorStore'dan ilgili dÃ¶kÃ¼manlarÄ± al
    docs = vectorstore_manager.similarity_search(last_message)
    context = "\n\n".join([doc.page_content for doc in docs])
    
    state["context"] = context
    return state


def search_web(state: AgentState) -> AgentState:
    """
    DuckDuckGo ile web'de arama yapar.
    
    Args:
        state: Mevcut agent state
        
    Returns:
        GÃ¼ncellenmiÅŸ state
    """
    if state["is_elasticsearch_related"]:
        return state
    
    last_message = state["messages"][-1].content
    
    if DEBUG:
        print("ğŸŒ Web'de arama yapÄ±lÄ±yor...")
    
    search_results = web_search.invoke(last_message)
    
    state["context"] = search_results
    return state


def generate_response(state: AgentState) -> AgentState:
    """
    Context'e dayanarak cevap Ã¼retir.
    
    Args:
        state: Mevcut agent state
        
    Returns:
        GÃ¼ncellenmiÅŸ state
    """
    last_message = state["messages"][-1].content
    context = state.get("context", "")
    
    if state["is_elasticsearch_related"]:
        prompt = f"""
        Sen Elasticsearch konusunda uzman bir asistansÄ±n. AÅŸaÄŸÄ±daki dÃ¶kÃ¼man bilgilerine dayanarak soruyu cevapla.
        
        DÃ¶kÃ¼man Bilgileri:
        {context}
        
        KullanÄ±cÄ± Sorusu: {last_message}
        
        LÃ¼tfen:
        - TÃ¼rkÃ§e ve detaylÄ± bir cevap ver
        - DÃ¶kÃ¼man bilgilerine sadÄ±k kal
        - Ã–rnekler ver
        - Teknik terimleri aÃ§Ä±kla
        """
    else:
        prompt = f"""
        Web aramasÄ± sonuÃ§larÄ±na dayanarak aÅŸaÄŸÄ±daki soruyu cevapla.
        
        Web Arama SonuÃ§larÄ±:
        {context}
        
        KullanÄ±cÄ± Sorusu: {last_message}
        
        LÃ¼tfen:
        - TÃ¼rkÃ§e ve Ã¶z bir cevap ver
        - GÃ¼venilir bilgiler sun
        - Gerekirse kaynaklarÄ± belirt
        """
    
    if DEBUG:
        print("ğŸ¤– Cevap Ã¼retiliyor...")
    
    response = llm.invoke(prompt)
    state["messages"].append(AIMessage(content=response.content))
    
    return state